library(gridExtra)
library(ggplot2)
# Dataset diamonds
data(diamonds)
# Histograma como plot1
plot1 <- qplot(price, data = diamonds, binwidth = 1000)
# ScatterPlot como plot2
plot2 <- qplot(carat, price, data = diamonds, colour = cut)
# Combina os 2 plots na mesma Ã¡rea
grid.arrange(plot1, plot2, ncol = 1)
ggplot(data = diamonds, aes(x = price, group = cut, fill = cut)) +
geom_density(adjust = 1.5)
ggplot(data = diamonds, aes(x = price, group = cut, fill = cut)) +
geom_density(adjust = 1.5 , alpha = 0.2)
ggplot(data = diamonds,aes(x = price, group = cut, fill = cut)) +
geom_density(adjust = 1.5, position = "fill")
install.packages("reshape2")
install.packages("plotly")
library(reshape2)
library(plotly)
install.packages("reshape2")
library(reshape2)
library(plotly)
sp <- ggplot(tips, aes(x = total_bill, y = tip/total_bill)) + geom_point(shape = 1)
sp + facet_grid(sex ~ .)
ggplotly()
sp + facet_grid(. ~ sex)
ggplotly()
sp + facet_wrap( ~ day, ncol = 2)
ggplotly()
ggplot(mpg, aes(displ, hwy)) + geom_point() + facet_wrap(~manufacturer)
ggplotly()
install.packages('lattice')
getwd()
library(lattice)
xyplot(data = iris, groups = Species, Sepal.Length ~Petal.Length)
#Scatterplot
splom(trees)
xyplot(data = iris, groups = Species, Sepal.Length ~Petal.Length)
?Titanic
barchart(Class ~ Freq | Sex + Age, data = as.data.frame(Titanic),
groups = Survived, stack = T, layout=c(4,1),
auto.key = list(title = 'Dados Titanic'), columns = 2)
barchart(Class ~ Freq | Sex + Age, data = as.data.frame(Titanic),
groups = Survived, stack = T, layout=c(4,1),
auto.key = list(title = 'Dados Titanic'), columns = 2),
scales = list(x = 'free'))
barchart(Class ~ Freq | Sex + Age, data = as.data.frame(Titanic),
groups = Survived, stack = T, layout=c(4,1),
auto.key = list(title = 'Dados Titanic', columns = 2),
scales = list(x = 'free'))
x = equal.count(rivers)
x
Petallength <-equal.count(iris$Petal.Length, 4)
Petallength
xyplot(Sepal.Length~Sepal.Width | Petallength, data=iris)
Petallength <-equal.count(iris$Petal.Length, 2)
Petallength
xyplot(Sepal.Length~Sepal.Width | Petallength, data=iris)
Petallength <-equal.count(iris$Petal.Length, 4)
Petallength
xyplot(Sepal.Length~Sepal.Width | Petallength, data=iris)
install.packages('ggmap')
install.packages('mapproj')
map1<-get_map(location='Brazil', zoom = 4)
library(ggmap)
library(mapproj)
map1<-get_map(location='Brazil', zoom = 4)
?get_map
map1<-get_map(location= 'Brazil', zoom = 4)
map1<-get_map(location= 'Sao Paulo', zoom = 4)
map1<-get_map(location = 'Brazil', zoom = 4)
map1<-get_map(location = c(lon = 14.2350, lat = 51.9253), zoom = 4)
map2<-get_map(location = c(lon = 54.5260, lat = 15.2551), zoom = 4)
ggmap(map1)
ggmap(map2)
map1<-get_map(location = c(lon = 51.9253 , lat =14.2350 ), zoom = 4)
ggmap(map1)
ggmap(map2)
ggmap(map1)
map2<-get_map(location = c(lon = 15.5260, lat = 15.2551), zoom = 4)
ggmap(map2)
map2<-get_map(location = c(lon = 54.5260, lat = 15.2551), zoom = 4)
map1<-get_map(location = c(lon = - 51.9253 , lat =-14.2350 ), zoom = 4)
ggmap(map1)
ggmap(map2)
map2<-get_map(location = c(lon = 54.5260, lat = 25.2551), zoom = 4)
ggmap(map2)
qmap('Recife')
qmap('L69 3GP', zoom = 16)
qmap('L69 3GP', zoom = 16, maptype = 'satellite')
?maptype
mapImageData1<- get_map(location = c(lon = -0.016179, lat= 51.538525),
color = 'color',
source = 'google',
maptype = 'satellite',
zoom = 17)
ggmap(mapImageData1,
extent = 'device',
ylab = 'Latitude',
xlab = 'Longitude')
mapImageData1<- get_map(location = c(lon = -0.016179, lat= 51.538525),
color = 'color',
source = 'google',
maptype = 'hybrid',
zoom = 17)
mapImageData1<- get_map(location = c(lon = -0.016179, lat= 51.538525),
color = 'color',
source = 'google',
maptype = 'hybrid',
zoom = 17)
ggmap(mapImageData1,
extent = 'device',
ylab = 'Latitude',
xlab = 'Longitude')
#Maps
install.packages('mapdata')
install.packages('maps')
install.packages("maps")
library(maps)
library(mapdata)
map('worldHires', 'Canada',
xlim = c(-141,-53),
ylim = c(40, 85),
col = 'gray90',
fill = TRUE)
?MAP
?map
help(package = 'maps')
install.packages('networkD3')
library(networkD3)
data(MisLinks, MisNodes)
forceNetwork(Links = MisLinks, Nodes = MisNodes, SOurce = 'source',
Target = 'target', Value = 'value', NodeID = 'name',
Group = 'group', opacity = 0.4)
forceNetwork(Links = MisLinks, Nodes = MisNodes, Source = 'source',
Target = 'target', Value = 'value', NodeID = 'name',
Group = 'group', opacity = 0.4)
?networkD3
#Criando dados
src<- c('A','A','A','A',
'B','B','C','C','D')
target<-c('B','C','D','J',
'E','F','G','H','I')
networkData <-data.frame(src, target)
#Plot
simpleNetwork(networkData)
#Heatmap
install.packages('heatmaply')
library(heatmaply)
heatmaply(mtcars, k_col = 2, k_row = 3) %>% layout(margin = list(l = 130, b=40))
install.packages('dygraphs')
library(dygraphs)
dygraph(nhtemp, main = 'Temperaturas')%>%
dyRangeSelector(dateWindow = c('1920-01-01','1960-01-01'))
install.packages('rmaps')
install.packages('googleVis')
library(googleVis)
# Criando um Datafrane
df = data.frame(Pais = c("BR", "CH", "AR"),
ExportaÃ§Ãµes = c(10,13,14),
ImportaÃ§Ãµes = c(23,12,32))
# Criando um Datafrane
df = data.frame(Pais = c("BR", "CH", "AR"),
Exportacoes = c(10,13,14),
Importacoes = c(23,12,32))
#Grafico de linha
Line<-gvisLineChart(df)
plot(Line)
Column <- gvisColumnChart(df)
plot(Column)
#Grafico barras horizontal
Bar<-gvisBarChart(df)
plot(Bar)
#Grafico barras horizontal
Pie<-gvisPieChart(df)
plot(Pie)
#Grafico barras horizontal
Pie<-gvisPieChart(CityPopularity)
plot(Pie)
# GrÃ¡ficos Combinados
Combo <- gvisComboChart(df, xvar = "Pais",
yvar = c("Exportacoes", "Importacoes"),
options = list(seriesType = "bars",
series='{1: {type:"line"}}'))
plot(Combo)
#Scatter chart
Scatter <- gvisScatterChart(women,
options=list(
legend="none",
lineWidth=2, pointSize=0,
title="Women", vAxis="{title:'weight (lbs)'}",
hAxis="{title:'height (in)'}",
width=300, height=300))
plot(Scatter)
#Buble
Bubble <- gvisBubbleChart(Fruits, idvar="Fruit",
xvar="Sales", yvar="Expenses",
colorvar="Year", sizevar="Profit",
options=list(
hAxis='{minValue:75, maxValue:125}'))
plot(Buble)
plot(Bubble)
# Customizando
M <- matrix(nrow=6,ncol=6)
M[col(M)==row(M)] <- 1:6
dat <- data.frame(X=1:6, M)
SC <- gvisScatterChart(dat,
options=list(
title="Customizing points",
legend="right",
pointSize=30,
series="{
0: { pointShape: 'circle' },
1: { pointShape: 'triangle' },
2: { pointShape: 'square' },
3: { pointShape: 'diamond' },
4: { pointShape: 'star' },
5: { pointShape: 'polygon' }
}"))
plot(SC)
# Gauge
Gauge <- gvisGauge(CityPopularity,
options=list(min=0, max=800, greenFrom=500,
greenTo=800, yellowFrom=300, yellowTo=500,
redFrom=0, redTo=300, width=400, height=300))
plot(Gauge)
# Mapas
Intensity <- gvisIntensityMap(df)
plot(Intensity)
# Geo Chart
Geo=gvisGeoChart(Exports, locationvar="Country",
colorvar="Profit",
options=list(projection="kavrayskiy-vii"))
plot(Geo)
# Google Maps
AndrewMap <- gvisMap(Andrew, "LatLong" , "Tip",
options=list(showTip=TRUE,
showLine=TRUE,
enableScrollWheel=TRUE,
mapType='terrain',
useMapTypeControl=TRUE))
plot(AndrewMap)
GeoStates <- gvisGeoChart(states, "state.name", "Illiteracy",
options=list(region="US",
displayMode="regions",
resolution="provinces",
width=600, height=400))
GeoStates <- gvisGeoChart(state, "state.name", "Illiteracy",
options=list(region="US",
displayMode="regions",
resolution="provinces",
width=600, height=400))
states <- data.frame(state.name, state.x77)
GeoStates <- gvisGeoChart(states, "state.name", "Illiteracy",
options=list(region="US",
displayMode="regions",
resolution="provinces",
width=600, height=400))
plot(GeoStates)
# Mais exemplos
demo(googleVis)
setwd("~/Data Science - Curso/PowerBI-DataScience-master/meuCurso/PowerBICap11")
getwd()
# Carregando o dataset
vendas <- read.csv("Vendas.csv", fileEncoding = "windows-1252")
# Resumo do dataset
View(vendas)
str(vendas)
summary(vendas$Valor)
summary(vendas$Custo)
mean(vendas$Valor)
mean(vendas$Custo)
mean(vendas$Valor, trim = 0.1)
mean(vendas$Valor, trim = 0.1) #corta os extremos, para não interferir
mean(vendas$Valor, na.rm = TRUE)#corta os valores missing
weighted.mean(vendas$Valor, w = vendas$Custo)
# Mediana
median(vendas$Valor)
median(vendas$Custo)
# Moda
# Criando uma função
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Obtendo a Moda
result <- getmode(vendas$Valor)
print(result)
# Criando gráfico de médias por Estado com ggplot2
install.packages("ggplot2")
library(ggplot2)
ggplot(vendas) + stat_summary(aes(x = vendas$Estado, y = vendas$Valor),
fun.y = mean, geom = "bar",
fill = "lightgreen", col = "grey50")
# Carregando o dataset
vendas <- read.csv("Vendas.csv", fileEncoding = "windows-1252")
# Resumo do dataset
View(vendas)
summary(vendas$Valor)
# Variância
var(vendas$Valor)
# Desvio Padrão
sd(vendas$Valor)
# Carregando o dataset
amostras <- read.csv("amostras.csv", fileEncoding = "windows-1252")
# Resumo do dataset
View(amostras)
# Carregando o dataset
amostras <- read.csv("amostras.csv", fileEncoding = "windows-1252")
str(amostras)
summary(amostras$AmostraA)
summary(amostras$AmostraB)
# Carregando o dataset
carros <- read.csv("carros.csv")
# Resumo dos dados
head(carros)
# Carregando o dataset
carros <- read.csv("carros.csv")
# Resumo dos dados
head(carros)
str(carros)
# Carregando o dataset
carros <- read.csv("carros.csv")
# Resumo dos dados
head(carros)
view(carros)
View(carros)
str(carros)
# Medidas de Tendência Central
summary(carros$ano)
summary(carros[c('preco', 'kilometragem')])
# Medidas de Tendência Central
summary(carros$ano)
summary(carros[c('preco', 'kilometragem')])
## Explorando variáveis numéricas
mean(carros$preco)
median(carros$preco)
quantile(carros$preco)
quantile(carros$preco, probs = c(0.01, 0.99))
quantile(carros$preco, seq(from = 0, to = 1, by = 0.20))
IQR(carros$preco) # Diferença entre Q3 e Q1
range(carros$preco)#amplitude
summary(carros$preco)
diff(range(carros$preco))
# Carregando e sumarizando os dados
dados <- read.table("usuarios.csv", dec = ".", sep = ",", h = T, fileEncoding = "windows-1252")
names(dados)
summary(dados$salario)
str(dados)
# Tabela de Frequências Absolutas
freq <- table(dados$grau_instrucao)
freq
# Tabela de Frequências Relativas
freq_rel <- prop.table(freq)
freq_rel
# Porcentagem (100 * freq_rel_table)
p_freq_rel <- 100 * prop.table(freq_rel)
p_freq_rel
# Adiciona linhas de total
freq <- c(freq, sum(freq))
freq_rel <- c(freq_rel, sum(freq_rel))
p_freq_rel <- c(p_freq_rel, sum(p_freq_rel))
names(freq)[4] <- "Total"
tabela_final
# Tabela final
tabela_final <- cbind(freq,
freq_rel = round(freq_rel, digits = 2),
p_freq_rel = round(p_freq_rel, digits = 2))
tabela_final
# Dados
my_vector = c(3,12,5,18,45)
names(my_vector) = c("A","B","C","D","E")
my_vector
# Barplot
barplot(my_vector)
# Barplot
barplot(my_vector)
barplot(my_vector, col = c(1,2,3,4,5) )
barplot(my_vector, col = rgb(0.5,0.1,0.6,0.6), xlab = "Categorias", ylab = "Valores", main = "Barplot em R" , ylim = c(0,60) )
png("barplot.png" , width = 480, height = 480 )
dev.off()
# Ggplot2
library(ggplot2)
head(mtcars)
ggplot(mtcars, aes(x=as.factor(cyl) )) +
geom_bar()
ggplot(mtcars, aes(x=as.factor(cyl), fill=as.factor(cyl) )) +
geom_bar( ) +
scale_fill_manual(values = c("red", "green", "blue") )
# Criando dados fake
data = data.frame(group = c("A ","B ","C ","D ") , value=c(33,62,56,67) )
# Barplot
ggplot(data, aes(x = group, y = value ,fill = group )) +
geom_bar(width = 0.85, stat="identity")
# Pie Chart
slices <- c(10, 12,4, 16, 8)
lbls <- c("US", "UK", "Australia", "Germany", "France")
pie(slices, labels = lbls, main = "Beer per Country")
# Pie Chart com percentuais
slices <- c(10, 12, 4, 16, 8)
lbls <- c("US", "UK", "Australia", "Germany", "France")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct)
lbls <- paste(lbls,"%",sep="")
pie(slices,labels = lbls, col=rainbow(length(lbls)),
main="Beer per Country")
# Pie Chart 3D
install.packages("plotrix")
library(plotrix)
slices <- c(10, 12, 4, 16, 8)
lbls <- c("US", "UK", "Australia", "Germany", "France")
pie3D(slices,labels=lbls,explode=0.1,
main="Beer per Country")
cars <- c(1, 3, 6, 4, 9)
trucks <- c(2, 5, 4, 5, 12)
# Plot
plot(cars, type="o", col="blue", ylim=c(0,12))
lines(trucks, type="o", pch=22, lty=2, col="red")
title(main="Autos", col.main="red", font.main=4)
# Boxplot
library(ggplot2)
# Plot
ggplot(mpg, aes(x=reorder(class, hwy), y=hwy, fill=class)) +
geom_boxplot() +
xlab("class") +
theme(legend.position="none")
data = data.frame(cond = rep(c("condition_1", "condition_2"), each=10),
my_x = 1:100 + rnorm(100,sd=9), my_y = 1:100 + rnorm(100,sd=16) )
ggplot(data, aes(x=my_x, y=my_y)) +
geom_point(shape=1)
# Adiciona linha de regressao
ggplot(data, aes(x=my_x, y=my_y)) +
geom_point(shape=1) +
geom_smooth(method = lm , color="red", se=FALSE)
# Adiciona smooth
ggplot(data, aes(x=my_x, y=my_y)) +
geom_point(shape=1) +
geom_smooth(method=lm , color="red", se=TRUE)
# Treemap
install.packages("treemap")
library(treemap)
# Dados
group=c(rep("group-1",4),rep("group-2",2),rep("group-3",3))
subgroup=paste("subgroup" , c(1,2,3,4,1,2,1,2,3), sep="-")
value=c(13,5,22,12,11,7,3,1,23)
data=data.frame(group,subgroup,value)
# Labels
treemap(data, index=c("group","subgroup"),
vSize="value", type="index",
fontsize.labels=c(15,12),
fontcolor.labels=c("white","orange"),
fontface.labels=c(2,1),
bg.labels=c("transparent"),
align.labels=list(
c("center", "center"),
c("right", "bottom")),
overlap.labels=0.5,
inflate.labels=F
)
# Customizando
treemap(data, index=c("group","subgroup"), vSize="value", type="index",
border.col=c("black","white"),
border.lwds=c(7,2)
)
# Histograma
x <- mtcars$mpg
h <- hist(x, breaks = 10, col="red", xlab = "Miles Per Gallon",
main = "Histograma com Curva de Distribuicao")
xfit <- seq(min(x),max(x),length=40)
yfit <- dnorm(xfit,mean=mean(x),sd=sd(x))
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)
# Usando o ggplot2
library(ggplot2)
# dataset
data = data.frame(value = rnorm(10000))
# Custom Binning. I can just give the size of the bin
ggplot(data, aes(x=value)) +
geom_histogram(binwidth = 0.05)
# Uniform color
ggplot(data, aes(x=value)) +
geom_histogram(binwidth = 0.2, color="white", fill=rgb(0.2,0.7,0.1,0.4) )
# Proportional color
ggplot(data, aes(x=value)) +
geom_histogram(binwidth = 0.2, aes(fill = ..count..) )
setwd("~/Data Science - Curso/PowerBI-DataScience-master/meuCurso/PowerBICap12")
getwd()
dbinom(3, size = 12, prob = 0.2)
# Uma vez que apenas uma entre cinco respostas possíveis está correta, a probabilidade de responder a
# uma pergunta corretamente por aleatoriedade é 1/5 = 0,2. Podemos encontrar a probabilidade de ter
# exatamente 3 respostas corretas por tentativas aleatórias como segue.
help(Binomial)
?dbinom
ppois(16, lambda = 12, lower = FALSE)
# A probabilidade de ter dezesseis ou menos carros cruzando a ponte em um minuto específico é dada pela
# função ppois.
ppois(16, lambda = 12)
# Aplicamos a função pnorm da distribuição normal com média 72 e desvio padrão 15,2. Uma vez que
# estamos procurando o percentual de alunos com pontuação superior a 84, estamos interessados na cauda
# superior da distribuição normal.
?pnorm
# A função tem este formato: pnorm(q, mean=0, sd=1) # Distribuição de Probabilidade Cumulativa
# Retorna P (X <= q), onde X é uma variável aleatória da distribuição normal especificada.
# A porcentagem de alunos com pontuação de 84 ou mais no vestibular é de 21,5%.
pnorm(84, mean = 72, sd = 15.2, lower.tail = FALSE)
# A função rnorm é usada para gerar números aleatórios cuja distribuição é normal.
# Recebe o tamanho da amostra como entrada e gera muitos números aleatórios.
# Criamos um histograma para mostrar a distribuição dos números gerados.
hist(rnorm(1000, mean = 3, sd = 0.25))
rnorm(1000, mean = 3, sd = 0.25)
?read
